{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22ccd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from yolo_predictions import YOLO_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae7f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO_Pred('./Model/weights/best.onnx','data.yaml.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2688feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./prediction_img.png')\n",
    "\n",
    "#cv2.imshow('img',img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2da584b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "img_pred = yolo.predictions(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0f06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('prediction image',img_pred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfbd9f",
   "metadata": {},
   "source": [
    "## Real Time Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13ba8d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munable to read video\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m pred_image \u001b[38;5;241m=\u001b[39m \u001b[43myolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYOLO\u001b[39m\u001b[38;5;124m'\u001b[39m,pred_image)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n",
      "File \u001b[1;32mD:\\yolo_v\\2_Predictions\\yolo_predictions.py:80\u001b[0m, in \u001b[0;36mYOLO_Pred.predictions\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     77\u001b[0m confidences_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(confidences)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# NMS\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNMSBoxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfidences_np\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.45\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m()\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Draw the Bounding\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m index:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# extract bounding box\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('video.mp4.mp4')\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        print('unable to read video')\n",
    "        break\n",
    "        \n",
    "    pred_image = yolo.predictions(frame)\n",
    "    \n",
    "    cv2.imshow('YOLO',pred_image)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d7a031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a09cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009a495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
